{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39d33024",
   "metadata": {},
   "source": [
    "In this notebook, we generate a Feed Forward Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9c4ad3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # Useful for running command line within python\n",
    "import pandas as pd ## Useful for data manipulation\n",
    "\n",
    "import torch ## Pytorch is the deep learning library that we will be using\n",
    "import torch.nn as nn # Neural network module\n",
    "import torch.nn.functional as F ## Functional module\n",
    "import torchmetrics ## Torchmetrics is a library that contains metrics for evaluating models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "#from torchvision.datasets.folder import default_loader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "import pytorch_lightning as pl ## Pytorch lightning is a wrapper for pytorch that makes it easier to train models\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks import Callback, ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "from torchmetrics.regression import MeanSquaredError\n",
    "\n",
    "from torch.nn import ReLU, Sequential\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ce8c277",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"./data/cleaned_data/86077_aws_plumber_data_inputs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4b2b144d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_range(inputs,historic, y1=1,y0=-1):\n",
    "    n_inputs=inputs.shape[1]\n",
    "    names_inputs=historic.columns\n",
    "    slope=torch.zeros(n_inputs)\n",
    "    b_array=torch.zeros(n_inputs)\n",
    "    for i in range(n_inputs):\n",
    "        x1=historic[names_inputs[i+1]][1]\n",
    "        x0=historic[names_inputs[i+1]][0]\n",
    "        slope[i]=(y1-y0)/(x1-x0)\n",
    "        b_array[i]=-x0*slope[i]+y0\n",
    "                    \n",
    "    return inputs*slope+b_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9668cff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now the idea is to generate datasets. Given that the csv are managble in size. The idea is create a pandas dataframe, then\n",
    "## construct a tensor with input features, and another tensor with right temperatures\n",
    "\n",
    "### Take this example. From https://discuss.pytorch.org/t/create-custom-dataset-from-tensors/122566/5\n",
    "#my_x = torch.stack([torch.rand(2,2),torch.rand(2,2)])\n",
    "#my_y = torch.stack([torch.rand(1), torch.rand(1)])\n",
    "#my_dataset = torch.utils.data.TensorDataset(my_x,my_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623dcc47",
   "metadata": {},
   "source": [
    "Construct the trainset, valset, and testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "80f67b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_output=pd.read_csv(\"./data/cleaned_data/86077_aws_plumber_data_outputs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a1c93a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature_24</th>\n",
       "      <th>temperature_48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.799999</td>\n",
       "      <td>19.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.400000</td>\n",
       "      <td>19.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.100000</td>\n",
       "      <td>19.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.900000</td>\n",
       "      <td>19.799999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.700001</td>\n",
       "      <td>19.799999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87469</th>\n",
       "      <td>25.600000</td>\n",
       "      <td>20.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87470</th>\n",
       "      <td>24.700001</td>\n",
       "      <td>20.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87471</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>20.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87472</th>\n",
       "      <td>22.400000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87473</th>\n",
       "      <td>21.700001</td>\n",
       "      <td>19.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87474 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       temperature_24  temperature_48\n",
       "0           17.799999       19.900000\n",
       "1           17.400000       19.100000\n",
       "2           17.100000       19.500000\n",
       "3           16.900000       19.799999\n",
       "4           16.700001       19.799999\n",
       "...               ...             ...\n",
       "87469       25.600000       20.600000\n",
       "87470       24.700001       20.600000\n",
       "87471       23.000000       20.500000\n",
       "87472       22.400000       20.000000\n",
       "87473       21.700001       19.500000\n",
       "\n",
       "[87474 rows x 2 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f31f0873",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We are creating a custom dataset class\n",
    "class WeatherData(Dataset):\n",
    "\n",
    "    def __init__(self, csv_inputs, csv_outputs,csv_historic,y1=1,y0=-1):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            csv_inputs (string): Path to the csv file of the inputs of the NN.\n",
    "            csv_outputs (string): Path to the csv file of temperatures 24 and 48 hours after measurement .\n",
    "            csv_historic (string): Path to the csv file of historic weather data.\n",
    "        \"\"\"\n",
    "        \n",
    "        input_data = pd.read_csv(csv_inputs)\n",
    "        output_data= pd.read_csv(csv_outputs)\n",
    "        historic= pd.read_csv(csv_historic)\n",
    "        \n",
    "        \n",
    "        ## Transform input data\n",
    "        n=len(input_data)\n",
    "        minutes=[datetime.datetime.strptime(input_data[\"local_time\"][i], '%Y-%m-%d %H:%M:%S').minute for i in range(n)]\n",
    "        input_data[\"local_time\"]=minutes\n",
    "        self.inputs=transform_to_range(torch.tensor(input_data.values.astype(np.float32)),historic,y1=y1,y0=y0)\n",
    "        \n",
    "        #Transform output data\n",
    "        x1_temperature=historic[\"Air_Temperature_in_degrees_C\"][1]\n",
    "        x0_temperature=historic[\"Air_Temperature_in_degrees_C\"][0]\n",
    "        slope_temperature=(y1-y0)/(x1_temperature-x0_temperature)\n",
    "        b_temperature=-x0_temperature*slope_temperature+y0\n",
    "        self.outputs=torch.tensor(output_data.values.astype(np.float32))*slope_temperature+b_temperature\n",
    "    \n",
    "        \n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx:int):\n",
    "        return self.inputs[idx],self.outputs[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7f3a1dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_86077=\"./data/cleaned_data/86077_aws_plumber_data_inputs.csv\"\n",
    "output_86077=\"./data/cleaned_data/86077_aws_plumber_data_outputs.csv\"\n",
    "historic_path=\"./data/cleaned_data/Historical_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3e9017da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=WeatherData(input_86077,output_86077,historic_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fab43349",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, valset = random_split(dataset, [0.8, 0.2]) ### I am just verifying that everything works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23da6dcf",
   "metadata": {},
   "source": [
    "Define dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a478edfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a batch size of 16.\n",
    "BATCH_SIZE = 128 #Just indicate the batch size\n",
    "\n",
    "# Create Dataloaders again with features generated from pre-trained CNN model.\n",
    "trainloader = DataLoader(dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5431dbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feed Forward Neural Network\n",
    "\n",
    "class feed_forward(pl.LightningModule):\n",
    "    def __init__(self, n, learning_rate=1e-2, traindataloader=None, valdataloader=None, testdataloader=None):\n",
    "        ## n is the number of inputs\n",
    "        super().__init__()\n",
    "        \n",
    "        # define learning rate\n",
    "        self.learning_rate = learning_rate ## Just the numerical value of the learning rate\n",
    "\n",
    "        # define loss function (Cross entropy loss)\n",
    "        self.loss_fun = nn.CrossEntropyLoss() ## The function to calculate the loss\n",
    "\n",
    "        # define neural layers\n",
    "        ## The architectures follows the NN defined in the Urban Heat Island paper about Athens \n",
    "        self.linear1 =  nn.Linear(n, 30) ## \n",
    "        self.linear2 =  nn.Linear(30, 30) ##\n",
    "        self.linear3= nn.Linear(30,1) ## This layer makes a prediction.\n",
    "        \n",
    "        # Create ReLU Activation Layer\n",
    "        self.relu=nn.ReLU() ####\n",
    "\n",
    "        # We calculate the mean square error as a perfomance metric\n",
    "        \n",
    "        self.train_mse = MeanSquaredError()\n",
    "        self.val_mse = MeanSquaredError()\n",
    "        self.test_mse = MeanSquaredError()\n",
    "\n",
    "        # Define dataloaders\n",
    "        self.traindataloader = traindataloader ### I am just passing the corresponding dataloader\n",
    "        self.valdataloader = valdataloader   ### I am just passing the corresponding dataloader\n",
    "        self.testdataloader = testdataloader ### I am just passing the corresponding dataloader\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        out1=self.relu(self.linear1(x))\n",
    "        out2=self.relu(self.linear2(out1))\n",
    "        out=self.linear3(out2)\n",
    "\n",
    "        return out # return the output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        # Make predictions\n",
    "        x,y=batch ## The batch should come from the CovidDataset class\n",
    "        # Do the prediction\n",
    "        \n",
    "        y_hat=self(x) ## This predicts the results from x\n",
    "\n",
    "        # Calculate the loss\n",
    "        # Apply the loss function here\n",
    "        loss=self.loss_fun(y_hat,y) ## Calculate the loss with the function declared in this class\n",
    "        ## Update the MSE\n",
    "        self.train_mse.update(y_hat, y)\n",
    "        \n",
    "        \n",
    "        # Record accuracy and loss\n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        # You may add more logs as you think necessary\n",
    "         \n",
    "        ### In the next two lines the history of the loss and accuracy is logged\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log(\"train_mse\", self.train_mse, prog_bar=True, on_step=False, on_epoch=True)\n",
    "\n",
    "        # Return the loss\n",
    "        return loss ## \n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \n",
    "        ### I am going to reuse the code for the training\n",
    "        x,y=batch \n",
    "        y_hat=self(x) ## This predicts the results from x\n",
    "\n",
    "        # Compute loss for each batch\n",
    "        loss=self.loss_fun(y_hat,y) ## Calculate the loss \n",
    "        ## Update the MSE\n",
    "        self.val_mse.update(y_hat, y)\n",
    "\n",
    "\n",
    "        # Record accuracy and loss\n",
    "        # Log anything you think necessary\n",
    "        ### Save the logs for the loss and for the accuracy\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log(\"val_mse\", self.val_mse, prog_bar=True, on_step=False, on_epoch=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        \n",
    "        x,y=batch \n",
    "        y_hat=self(x) ## This predicts the results from x\n",
    "\n",
    "        # Compute loss for each batch\n",
    "        loss=self.loss_fun(y_hat,y) ## Calculate the loss \n",
    "\n",
    "        self.test_mse.update(y_hat, y) \n",
    "\n",
    "        # Record accuracy and loss\n",
    "        # Log anything you think necessary\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log(\"test_mse\", self.test_mse, prog_bar=True, on_step=False, on_epoch=True)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        \n",
    "        x,y=batch\n",
    "        # Do prediction\n",
    "        y_hat=self(x)\n",
    "\n",
    "        return y_hat,y,x # Return prediction, actual value and inputs  \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # define optimizer\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    ####################\n",
    "    # DATA RELATED HOOKS\n",
    "    ####################\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        # return the train dataloader\n",
    "        return  self.traindataloader ## Just return the traindataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        # return the validation dataloader\n",
    "        return self.valdataloader  ### Just return the valdataloader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        # return the test dataloader\n",
    "        return self.testdataloader  ## Just return the testdataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11e8f47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
