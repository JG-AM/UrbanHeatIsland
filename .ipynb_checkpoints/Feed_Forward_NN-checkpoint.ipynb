{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39d33024",
   "metadata": {},
   "source": [
    "In this notebook, we generate a Feed Forward Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9c4ad3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # Useful for running command line within python\n",
    "import pandas as pd ## Useful for data manipulation\n",
    "\n",
    "import torch ## Pytorch is the deep learning library that we will be using\n",
    "import torch.nn as nn # Neural network module\n",
    "import torch.nn.functional as F ## Functional module\n",
    "import torchmetrics ## Torchmetrics is a library that contains metrics for evaluating models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets.folder import default_loader\n",
    "\n",
    "import pytorch_lightning as pl ## Pytorch lightning is a wrapper for pytorch that makes it easier to train models\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks import Callback, ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "from torchmetrics.regression import MeanSquaredError\n",
    "\n",
    "from torch.nn import ReLU, Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95769783",
   "metadata": {},
   "source": [
    "I need to load the trainset, valset, and testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ce8c277",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"./data/cleaned_data/86077_aws_plumber_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23da6dcf",
   "metadata": {},
   "source": [
    "Define dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac3cab52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1.468085\n",
       "1        1.468085\n",
       "2        1.855263\n",
       "3        1.553192\n",
       "4        1.947368\n",
       "           ...   \n",
       "87595    1.119565\n",
       "87596    1.584615\n",
       "87597    1.830357\n",
       "87598    1.538462\n",
       "87599    1.500000\n",
       "Length: 87600, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data[\"Precipitation_since_9am_local_time_in_mm\"]+data[\"Air_Temperature_in_degrees_C\"])/data[\"Wind_speed_in_kmh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad739441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        3.065942\n",
       "1        3.065942\n",
       "2        2.756810\n",
       "3        3.065942\n",
       "4        2.756810\n",
       "           ...   \n",
       "87595    4.289522\n",
       "87596    3.605551\n",
       "87597    3.346640\n",
       "87598    3.605551\n",
       "87599    3.605551\n",
       "Name: Wind_speed_in_kmh, Length: 87600, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(data[\"Wind_speed_in_kmh\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9971ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "086828a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4680851063829787"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13.8/9.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fe4099d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.855263157894737"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14.1/7.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5431dbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feed Forward Neural Network\n",
    "\n",
    "class feed_forward(pl.LightningModule):\n",
    "    def __init__(self, n, learning_rate=1e-2, traindataloader=None, valdataloader=None, testdataloader=None):\n",
    "        ## n is the number of inputs\n",
    "        super().__init__()\n",
    "        \n",
    "        # define learning rate\n",
    "        self.learning_rate = learning_rate ## Just the numerical value of the learning rate\n",
    "\n",
    "        # define loss function (Cross entropy loss)\n",
    "        self.loss_fun = nn.CrossEntropyLoss() ## The function to calculate the loss\n",
    "\n",
    "        # define neural layers\n",
    "        ## The architectures follows the NN defined in the Urban Heat Island paper about Athens \n",
    "        self.linear1 =  nn.Linear(n, 30) ## \n",
    "        self.linear2 =  nn.Linear(30, 30) ##\n",
    "        self.linear3= nn.Linear(30,1) ## This layer makes a prediction.\n",
    "        \n",
    "        # Create ReLU Activation Layer\n",
    "        self.relu=nn.ReLU() ####\n",
    "\n",
    "        # We calculate the mean square error as a perfomance metric\n",
    "        \n",
    "        self.train_mse = MeanSquaredError()\n",
    "        self.val_mse = MeanSquaredError()\n",
    "        self.test_mse = MeanSquaredError()\n",
    "\n",
    "        # Define dataloaders\n",
    "        self.traindataloader = traindataloader ### I am just passing the corresponding dataloader\n",
    "        self.valdataloader = valdataloader   ### I am just passing the corresponding dataloader\n",
    "        self.testdataloader = testdataloader ### I am just passing the corresponding dataloader\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        out1=self.relu(self.linear1(x))\n",
    "        out2=self.relu(self.linear2(out1))\n",
    "        out=self.linear3(out2)\n",
    "\n",
    "        return out # return the output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        # Make predictions\n",
    "        x,y=batch ## The batch should come from the CovidDataset class\n",
    "        # Do the prediction\n",
    "        \n",
    "        y_hat=self(x) ## This predicts the results from x\n",
    "\n",
    "        # Calculate the loss\n",
    "        # Apply the loss function here\n",
    "        loss=self.loss_fun(y_hat,y) ## Calculate the loss with the function declared in this class\n",
    "        ## Update the MSE\n",
    "        self.train_mse.update(y_hat, y)\n",
    "        \n",
    "        \n",
    "        # Record accuracy and loss\n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        # You may add more logs as you think necessary\n",
    "         \n",
    "        ### In the next two lines the history of the loss and accuracy is logged\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log(\"train_mse\", self.train_mse, prog_bar=True, on_step=False, on_epoch=True)\n",
    "\n",
    "        # Return the loss\n",
    "        return loss ## \n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \n",
    "        ### I am going to reuse the code for the training\n",
    "        x,y=batch \n",
    "        y_hat=self(x) ## This predicts the results from x\n",
    "\n",
    "        # Compute loss for each batch\n",
    "        loss=self.loss_fun(y_hat,y) ## Calculate the loss \n",
    "        ## Update the MSE\n",
    "        self.val_mse.update(y_hat, y)\n",
    "\n",
    "\n",
    "        # Record accuracy and loss\n",
    "        # Log anything you think necessary\n",
    "        ### Save the logs for the loss and for the accuracy\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log(\"val_mse\", self.val_mse, prog_bar=True, on_step=False, on_epoch=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        \n",
    "        x,y=batch \n",
    "        y_hat=self(x) ## This predicts the results from x\n",
    "\n",
    "        # Compute loss for each batch\n",
    "        loss=self.loss_fun(y_hat,y) ## Calculate the loss \n",
    "\n",
    "        self.test_mse.update(y_hat, y) \n",
    "\n",
    "        # Record accuracy and loss\n",
    "        # Log anything you think necessary\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log(\"test_mse\", self.test_mse, prog_bar=True, on_step=False, on_epoch=True)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        \n",
    "        x,y=batch\n",
    "        # Do prediction\n",
    "        y_hat=self(x)\n",
    "\n",
    "        return y_hat,y,x # Return prediction, actual value and inputs  \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # define optimizer\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    ####################\n",
    "    # DATA RELATED HOOKS\n",
    "    ####################\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        # return the train dataloader\n",
    "        return  self.traindataloader ## Just return the traindataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        # return the validation dataloader\n",
    "        return self.valdataloader  ### Just return the valdataloader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        # return the test dataloader\n",
    "        return self.testdataloader  ## Just return the testdataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11e8f47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
