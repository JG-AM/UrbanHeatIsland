{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import netCDF4\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil import tz\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_locations = {\n",
    "    'Melbourne Airport': {'station_id':86282, },\n",
    "    'Moorabbin Airport': {'station_id':86077, },\n",
    "    'Laverton RAAF': {'station_id':87031, },\n",
    "}\n",
    "\n",
    "aws_data_dir = 'data/raw_data/weather_station_data/'\n",
    "plumber_data_dir = \"data/raw_data/AU-Preston/timeseries/\"\n",
    "\n",
    "out_data_dir = 'data/cleaned_data/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Small function to return dte time from the nc file as the nc file has date as seconds from a baseline\n",
    "## Need tro convert to UTC time\n",
    "\n",
    "def return_date_from_seconds(nc_data, seconds_to_add):\n",
    "    nc_start = datetime.strptime(nc_data.variables[\"time\"].units[14:], '%Y-%m-%d %H:%M:%S')\n",
    "    new_time = nc_start + timedelta(seconds=int(seconds_to_add))\n",
    "\n",
    "    return new_time\n",
    "\n",
    "def return_seconds_since_date(nc_data, date):\n",
    "    ## USe this as less loops\n",
    "    nc_start = datetime.strptime(nc_data.variables[\"time\"].units[14:], '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    ## Convert from local time > UTC (https://stackoverflow.com/questions/4770297/convert-utc-datetime-string-to-local-datetime)\n",
    "    to_zone = tz.gettz(\"Australia/Melbourne\")\n",
    "    from_zone = tz.gettz('UTC')\n",
    "\n",
    "    nc_start = nc_start.replace(tzinfo=from_zone)\n",
    "    # Convert time zone\n",
    "    nc_start = nc_start.astimezone(to_zone)\n",
    "    nc_start = nc_start.replace(tzinfo=None)\n",
    "    # print(nc_start)\n",
    "\n",
    "    time_diff = date - nc_start\n",
    "    time_diff = time_diff.total_seconds()\n",
    "\n",
    "    return int(time_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean data for one station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melbourne Airport 86282\n",
      "Moorabbin Airport 86077\n",
      "Laverton RAAF 87031\n"
     ]
    }
   ],
   "source": [
    "## Read the plumber data (.nc)\n",
    "plumber_fpath = f\"{plumber_data_dir}AU-Preston_metforcing_v1.nc\"\n",
    "preston_data = netCDF4.Dataset(plumber_fpath)\n",
    "\n",
    "## Loop through each location to produce a clean dataset\n",
    "for loc in aws_locations:\n",
    "    station_id = aws_locations[loc]['station_id']\n",
    "    print(loc, station_id)\n",
    "\n",
    "    # Read AWS data (csv)\n",
    "    csv_file = f\"{aws_data_dir}{station_id}_data.csv\"\n",
    "    aws_df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Filling missing values and convert data type to float\n",
    "    aws_df['Precipitation_since_9am_local_time_in_mm'] = aws_df['Precipitation_since_9am_local_time_in_mm'].interpolate(method='linear').fillna(aws_df['Precipitation_since_9am_local_time_in_mm'].mean()).astype(float)\n",
    "\n",
    "    aws_df['Air_Temperature_in_degrees_C'] = aws_df['Air_Temperature_in_degrees_C'].interpolate(method='linear').fillna(aws_df['Air_Temperature_in_degrees_C'].mean()).astype(float)\n",
    "\n",
    "    aws_df['Relative_humidity_in_percentage'] = aws_df['Relative_humidity_in_percentage'].interpolate(method='linear').fillna(aws_df['Relative_humidity_in_percentage'].mean()).astype(float)\n",
    "\n",
    "    aws_df['Wind_speed_in_kmh'] = aws_df['Wind_speed_in_kmh'].interpolate(method='linear').fillna(aws_df['Wind_speed_in_kmh'].mean()).astype(float)\n",
    "    \n",
    "    aws_df['Mean_sea_level_pressure_in_hPa'] = aws_df['Mean_sea_level_pressure_in_hPa'].interpolate(method='linear').fillna(aws_df['Mean_sea_level_pressure_in_hPa'].mean()).astype(float)\n",
    "\n",
    "    # drop the standard time column as we will be sticking to local time (AEST/AEDT)\n",
    "    aws_df = aws_df.drop(columns=['standard_time'])\n",
    "\n",
    "    # Converting the time stamps to date time \n",
    "    aws_df[\"local_time\"] = pd.to_datetime(aws_df[\"local_time\"])\n",
    "\n",
    "    nc_swdown = preston_data.variables[\"SWdown\"][:]\n",
    "    nc_lwdown = preston_data.variables[\"LWdown\"][:]\n",
    "    nc_windN = preston_data.variables[\"Wind_N\"][:]\n",
    "    nc_windE = preston_data.variables[\"Wind_E\"][:]\n",
    "\n",
    "    time_values = preston_data.variables[\"time\"][:]\n",
    "    # print(preston_data.variables[\"time\"].units[14:])\n",
    "\n",
    "    # temporary arrays to store the needed values \n",
    "    temp_swdown = []\n",
    "    temp_lwdown = []\n",
    "    temp_windN = []\n",
    "    temp_windE = []\n",
    "\n",
    "    ## Now loop through the csv file and get the relevant index in the data array\n",
    "    for index,row in aws_df.iterrows():\n",
    "        # print(row['standard_time'])\n",
    "        seconds_since_start = return_seconds_since_date(preston_data, row['local_time'])\n",
    "\n",
    "        idx = np.where(time_values == seconds_since_start)\n",
    "\n",
    "        temp_swdown.append(nc_swdown[idx][0][0][0])\n",
    "        temp_lwdown.append(nc_lwdown[idx][0][0][0])\n",
    "        temp_windN.append(nc_windN[idx][0][0][0])\n",
    "        temp_windE.append(nc_windE[idx][0][0][0])\n",
    "\n",
    "    aws_df['swdown'] = temp_swdown\n",
    "    aws_df['lwdown'] = temp_lwdown\n",
    "    aws_df['windN'] = temp_windN\n",
    "    aws_df['windE'] = temp_windE\n",
    "\n",
    "    ## Extract month and time of day (hour of day)\n",
    "    aws_df['month_of_year'] = aws_df['local_time'].dt.month\n",
    "    aws_df['hour_of_day'] = aws_df['local_time'].dt.hour\n",
    "\n",
    "    ## Calculating wind direction based on windN and windE\n",
    "    # https://stackoverflow.com/questions/21484558/how-to-calculate-wind-direction-from-u-and-v-wind-components-in-r\n",
    "    #https://www.eol.ucar.edu/content/wind-direction-quick-reference\n",
    "    wind_abs = np.sqrt(aws_df['windE'].values**2 + aws_df['windN'].values**2)\n",
    "    # wind_dir_trig_to = math.atan2(aws_df['windE'].values/wind_abs, aws_df['windN'].values/wind_abs) \n",
    "    wind_dir_trig_to = np.arctan2(-aws_df['windN'].values, -aws_df['windE'].values) \n",
    "    wind_dir_trig_to_degrees = wind_dir_trig_to * 180/math.pi\n",
    "    wind_dir_trig_from_degrees = wind_dir_trig_to_degrees + 180\n",
    "    wind_dir_cardinal = 90 - wind_dir_trig_from_degrees\n",
    "\n",
    "    # make sure direction is computed form N>E>S>W\n",
    "    for w in range(len(wind_dir_cardinal)):\n",
    "        if (wind_dir_cardinal[w] < 0):\n",
    "            wind_dir_cardinal[w] = wind_dir_cardinal[w] + 360\n",
    "\n",
    "    aws_df['wind_direction'] = wind_dir_cardinal\n",
    "\n",
    "    # Drop the wind components\n",
    "    aws_df = aws_df.drop(columns=['windE', 'windN'])\n",
    "\n",
    "    # Save the processed file\n",
    "    aws_df.to_csv(f\"{out_data_dir}{station_id}_aws_plumber_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of saving the direction and the speed of the wind. It is better to save the north and east components. The direction can be misleading because angles 0.01 and -0.01 are close but if the direction is defined as a number between 0 and 360 then these direction will be far.\n",
    "\n",
    "I have seen that you are supposing that the direction of the wind is the same in all locations. I am going to continue with the same assumption. But, I am going to modify the components to adjust the speed to the measured speed. The csv file will contain the components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melbourne Airport 86282\n",
      "Moorabbin Airport 86077\n",
      "Laverton RAAF 87031\n"
     ]
    }
   ],
   "source": [
    "## Read the plumber data (.nc)\n",
    "plumber_fpath = f\"{plumber_data_dir}AU-Preston_metforcing_v1.nc\"\n",
    "preston_data = netCDF4.Dataset(plumber_fpath)\n",
    "\n",
    "## Loop through each location to produce a clean dataset\n",
    "for loc in aws_locations:\n",
    "    station_id = aws_locations[loc]['station_id']\n",
    "    print(loc, station_id)\n",
    "\n",
    "    # Read AWS data (csv)\n",
    "    csv_file = f\"{aws_data_dir}{station_id}_data.csv\"\n",
    "    aws_df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Filling missing values and convert data type to float\n",
    "    aws_df['Precipitation_since_9am_local_time_in_mm'] = aws_df['Precipitation_since_9am_local_time_in_mm'].interpolate(method='linear').fillna(aws_df['Precipitation_since_9am_local_time_in_mm'].mean()).astype(float)\n",
    "\n",
    "    aws_df['Air_Temperature_in_degrees_C'] = aws_df['Air_Temperature_in_degrees_C'].interpolate(method='linear').fillna(aws_df['Air_Temperature_in_degrees_C'].mean()).astype(float)\n",
    "\n",
    "    aws_df['Relative_humidity_in_percentage'] = aws_df['Relative_humidity_in_percentage'].interpolate(method='linear').fillna(aws_df['Relative_humidity_in_percentage'].mean()).astype(float)\n",
    "\n",
    "    aws_df['Wind_speed_in_kmh'] = aws_df['Wind_speed_in_kmh'].interpolate(method='linear').fillna(aws_df['Wind_speed_in_kmh'].mean()).astype(float)\n",
    "    \n",
    "    aws_df['Mean_sea_level_pressure_in_hPa'] = aws_df['Mean_sea_level_pressure_in_hPa'].interpolate(method='linear').fillna(aws_df['Mean_sea_level_pressure_in_hPa'].mean()).astype(float)\n",
    "\n",
    "    # drop the standard time column as we will be sticking to local time (AEST/AEDT)\n",
    "    aws_df = aws_df.drop(columns=['standard_time'])\n",
    "\n",
    "    # Converting the time stamps to date time \n",
    "    aws_df[\"local_time\"] = pd.to_datetime(aws_df[\"local_time\"])\n",
    "\n",
    "    nc_swdown = preston_data.variables[\"SWdown\"][:]\n",
    "    nc_lwdown = preston_data.variables[\"LWdown\"][:]\n",
    "    nc_windN = preston_data.variables[\"Wind_N\"][:]\n",
    "    nc_windE = preston_data.variables[\"Wind_E\"][:]\n",
    "\n",
    "    time_values = preston_data.variables[\"time\"][:]\n",
    "    # print(preston_data.variables[\"time\"].units[14:])\n",
    "\n",
    "    # temporary arrays to store the needed values \n",
    "    temp_swdown = []\n",
    "    temp_lwdown = []\n",
    "    temp_windN = []\n",
    "    temp_windE = []\n",
    "\n",
    "    ## Now loop through the csv file and get the relevant index in the data array\n",
    "    for index,row in aws_df.iterrows():\n",
    "        # print(row['standard_time'])\n",
    "        seconds_since_start = return_seconds_since_date(preston_data, row['local_time'])\n",
    "\n",
    "        idx = np.where(time_values == seconds_since_start)\n",
    "\n",
    "        temp_swdown.append(nc_swdown[idx][0][0][0])\n",
    "        temp_lwdown.append(nc_lwdown[idx][0][0][0])\n",
    "        temp_windN.append(nc_windN[idx][0][0][0])\n",
    "        temp_windE.append(nc_windE[idx][0][0][0])\n",
    "\n",
    "    aws_df['swdown'] = temp_swdown\n",
    "    aws_df['lwdown'] = temp_lwdown\n",
    "    aws_df['windN'] = temp_windN\n",
    "    aws_df['windE'] = temp_windE\n",
    "\n",
    "    ## Extract month and time of day (hour of day)\n",
    "    aws_df['month_of_year'] = aws_df['local_time'].dt.month\n",
    "    aws_df['hour_of_day'] = aws_df['local_time'].dt.hour\n",
    "\n",
    "    # Adjust the components\n",
    "    aws_df[\"windN\"]=aws_df[\"windN\"]*aws_df['Wind_speed_in_kmh']/(np.sqrt(aws_df[\"windN\"]**2+aws_df[\"windE\"]**2))\n",
    "    aws_df[\"windE\"]=aws_df[\"windE\"]*aws_df['Wind_speed_in_kmh']/(np.sqrt(aws_df[\"windN\"]**2+aws_df[\"windE\"]**2))\n",
    "    \n",
    "\n",
    "    # Drop the wind components\n",
    "    aws_df = aws_df.drop(columns=['Wind_speed_in_kmh'])\n",
    "\n",
    "    # Save the processed file\n",
    "    aws_df.to_csv(f\"{out_data_dir}{station_id}_aws_plumber_data_wind.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
